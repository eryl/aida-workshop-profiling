{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJRIC2orHBHt"
      },
      "source": [
        "# Optimizing training\n",
        "\n",
        "In this notebook we'll look at how we can optimize an experiment. We'll use this notebook more like an interactive shell, the code will be in batch scripts which you can download inside this notebook. Note that this assumes a linux environment where the necessary python dependencies are already installed. If you run this locally, it is suggested that you create a conda environment using the `environment.yml` in this repository.\n",
        "\n",
        "Exectute the following cell if you are running this on colab to copy the training scripts to the virtual machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HavisKCyHBHw",
        "outputId": "b3eb67b0-b904-497e-e57c-65f81584142b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'aida-workshop-profiling'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 11 (delta 1), reused 11 (delta 1), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (11/11), 4.05 KiB | 4.05 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/eryl/aida-workshop-profiling.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting a Linux computer\n",
        "\n",
        "In the background, colab is running on a virtual linux machine. We typically can only use it through the notebook interface unless we have a pro account, but there's a useful utility called colab-xterm which allows us to open a terminal inside a jupyter cell and essentially pretend like we're using a regular linux computer. This is what we will do. After that you can follow the instructions in the README of the main github repository."
      ],
      "metadata": {
        "id": "WGrbO2LHLT2g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### installing colab-xterm\n",
        "Installing colab-xterm is very simple, we just use `pip`:"
      ],
      "metadata": {
        "id": "X_HXlyraNqRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-xterm\n",
        "%load_ext colabxterm"
      ],
      "metadata": {
        "id": "tPqoQtsLNwtn",
        "outputId": "3530ad7e-c4de-412f-f426-d8674a8cfb08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: colab-xterm in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: ptyprocess~=0.7.0 in /usr/local/lib/python3.10/dist-packages (from colab-xterm) (0.7.0)\n",
            "Requirement already satisfied: tornado>5.1 in /usr/local/lib/python3.10/dist-packages (from colab-xterm) (6.3.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can now create as many terminals as you like by using the `%xterm` jupyter command."
      ],
      "metadata": {
        "id": "0QHiMsoqN0UP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Workshop tools\n",
        "\n",
        "We'll also take the opportunity to install some workshop tools, mainly `nvitop` to monitor CPU/GPU usage and `line_profiler` to profile our script."
      ],
      "metadata": {
        "id": "9QCjc2LlOBqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade nvitop"
      ],
      "metadata": {
        "id": "qmQNTQ56JlGH",
        "outputId": "6801061b-a2a0-44f5-d3ca-655c9739c0f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvitop\n",
            "  Downloading nvitop-1.3.2-py3-none-any.whl (215 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/215.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/215.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.4/215.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-ml-py<12.536.0a0,>=11.450.51 (from nvitop)\n",
            "  Downloading nvidia_ml_py-12.535.133-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: psutil>=5.6.6 in /usr/local/lib/python3.10/dist-packages (from nvitop) (5.9.5)\n",
            "Requirement already satisfied: cachetools>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from nvitop) (5.3.3)\n",
            "Requirement already satisfied: termcolor>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from nvitop) (2.4.0)\n",
            "Installing collected packages: nvidia-ml-py, nvitop\n",
            "Successfully installed nvidia-ml-py-12.535.133 nvitop-1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install line_profiler"
      ],
      "metadata": {
        "id": "sHAEC78wMCXe",
        "outputId": "e218ed91-a29f-4a94-f4bd-083851fabfc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: line_profiler in /usr/local/lib/python3.10/dist-packages (4.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaSaiDpsHBHx"
      },
      "source": [
        "## Monitoring GPU usage\n",
        "We're now ready to get started. Open a terminal by first running `%xterm`. When you've done that you'll be met with a terminal.\n",
        "\n",
        "Now start a \"virtual\" terminal by running:\n",
        "\n",
        "```bash\n",
        "$ tmux\n",
        "```\n",
        "This starts a virtual terminal manager which is not directly connected to the actual xterm. It's a relly good tool to know about, but we're only using it to make `nvitop` display properly.\n",
        "\n",
        "Once `tmux` is started you can start `nvitop`:\n",
        "```bash\n",
        "$ nvitop\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%xterm"
      ],
      "metadata": {
        "id": "B-ovjIy5LHrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can now have this terminal open, it will run independently from anything you are doing in the notebook. We'll start a second terminal to do our training in by running `%xterm` below.\n",
        "\n",
        "Navigate to the workshop directory:\n",
        "```bash\n",
        "$ cd /content/aida-workshop-profiling\n",
        "```\n",
        "\n",
        "Now we're ready to start exploring."
      ],
      "metadata": {
        "id": "U4HinDKcPe9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%xterm"
      ],
      "metadata": {
        "id": "4VNiuNwVNNN_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}